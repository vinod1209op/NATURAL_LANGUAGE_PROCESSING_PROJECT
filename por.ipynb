{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
    "df.columns = ['label', 'message']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4825   4516                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label'). describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer as Stemmer\n",
    "def process(text):\n",
    "    #Lowercase it \n",
    "    text = text. lower() \n",
    "    #remove punctuation\n",
    "    text = ''.join([t for t in text if t not in string.punctuation])\n",
    "    #remove stopwords \n",
    "    text = [t for t in text.split() if t not in stopwords.words('english')]\n",
    "    #stemming\n",
    "    st = Stemmer() \n",
    "    text = [st.stem(t) for t in text] \n",
    "    #return token list\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['holiday', 'play', 'cricket', 'jeff', 'play', 'well']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process('It\\'s holiday and we are playing cricket. Jeff is playing very well!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vinodrongala/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [go, jurong, point, crazi, avail, bugi, n, gre...\n",
       "1                          [ok, lar, joke, wif, u, oni]\n",
       "2     [free, entri, 2, wkli, comp, win, fa, cup, fin...\n",
       "3         [u, dun, say, earli, hor, u, c, alreadi, say]\n",
       "4     [nah, dont, think, goe, usf, live, around, tho...\n",
       "5     [freemsg, hey, darl, 3, week, word, back, id, ...\n",
       "6     [even, brother, like, speak, treat, like, aid,...\n",
       "7     [per, request, mell, mell, oru, minnaminungint...\n",
       "8     [winner, valu, network, custom, select, receiv...\n",
       "9     [mobil, 11, month, u, r, entitl, updat, latest...\n",
       "10    [im, gonna, home, soon, dont, want, talk, stuf...\n",
       "11    [six, chanc, win, cash, 100, 20000, pound, txt...\n",
       "12    [urgent, 1, week, free, membership, å£100000, ...\n",
       "13    [ive, search, right, word, thank, breather, pr...\n",
       "14                                       [date, sunday]\n",
       "15    [xxxmobilemovieclub, use, credit, click, wap, ...\n",
       "16                                     [oh, kim, watch]\n",
       "17    [eh, u, rememb, 2, spell, name, ye, v, naughti...\n",
       "18    [fine, thatåõ, way, u, feel, thatåõ, way, gota...\n",
       "19    [england, v, macedonia, dont, miss, goalsteam,...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message'][:20].apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfv = TfidfVectorizer(analyzer = process) \n",
    "data = tfidfv.fit_transform(df['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "mess = df.iloc[2]['message']\n",
    "print(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "spam_filter = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer=process)), #messages to weighted TFIDF score\n",
    "    ('classifier', MultinomialNB())                    #train on TFIDF vectors with Naive Bayes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.20, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer=<function process at 0x7fab52161ee0>)),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_filter.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = spam_filter.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test cases 1115\n",
      "Number of wrong of predictions 39\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test.iloc[i] != predictions[i]:\n",
    "        count += 1 \n",
    "print('Total number of test cases', len(y_test)) \n",
    "print('Number of wrong of predictions', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419     Send a logo 2 ur lover - 2 names joined by a h...\n",
       "3139    sexy sexy cum and text me im wet and warm and ...\n",
       "3790    Twinks, bears, scallies, skins and jocks are c...\n",
       "2877    Hey Boys. Want hot XXX pics sent direct 2 ur p...\n",
       "2377    YES! The only place in town to meet exciting a...\n",
       "1499    SMS. ac JSco: Energy is high, but u may not kn...\n",
       "3417    LIFE has never been this much fun and great un...\n",
       "3358    Sorry I missed your call let's talk when you h...\n",
       "2412    I don't know u and u don't know me. Send CHAT ...\n",
       "3862    Oh my god! I've found your number again! I'm s...\n",
       "659     88800 and 89034 are premium phone services cal...\n",
       "3109    Good Luck! Draw takes place 28th Feb 06. Good ...\n",
       "5466    http//tms. widelive.com/index. wml?id=820554ad...\n",
       "1268    Can U get 2 phone NOW? I wanna chat 2 set up m...\n",
       "491     Congrats! 1 year special cinema pass for 2 is ...\n",
       "2246    Hi ya babe x u 4goten bout me?' scammers getti...\n",
       "2828    Send a logo 2 ur lover - 2 names joined by a h...\n",
       "3528    Xmas & New Years Eve tickets are now on sale f...\n",
       "4247    accordingly. I repeat, just text the word ok o...\n",
       "4142    In The Simpsons Movie released in July 2007 na...\n",
       "3979                                   ringtoneking 84484\n",
       "1637    0A$NETWORKS allow companies to bill for SMS, s...\n",
       "2802                    FreeMsg>FAV XMAS TONES!Reply REAL\n",
       "3270    You have 1 new voicemail. Please call 08719181...\n",
       "2294     You have 1 new message. Please call 08718738034.\n",
       "2619    <Forwarded from 21870000>Hi - this is your Mai...\n",
       "234     Text & meet someone sexy today. U can find a d...\n",
       "760     Romantic Paris. 2 nights, 2 flights from å£79 ...\n",
       "138     You'll not rcv any more msgs from the chat svc...\n",
       "689     <Forwarded from 448712404000>Please CALL 08712...\n",
       "879     U have a Secret Admirer who is looking 2 make ...\n",
       "1216    You have 1 new voicemail. Please call 08719181...\n",
       "1892    CALL 09090900040 & LISTEN TO EXTREME DIRTY LIV...\n",
       "2351    Download as many ringtones as u like no restri...\n",
       "1317    Win the newest ÛÏHarry Potter and the Order o...\n",
       "4458    Welcome to UK-mobile-date this msg is FREE giv...\n",
       "1879    U have a secret admirer who is looking 2 make ...\n",
       "4309    Someone U know has asked our dating service 2 ...\n",
       "1673    Monthly password for wap. mobsi.com is 391784....\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[y_test != predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.96      0.98      1014\n",
      "        spam       0.72      1.00      0.84       101\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.86      0.98      0.91      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_spam(s):\n",
    "    return spam_filter.predict([s])[0] \n",
    "detect_spam(\"you won 1000 prize bonus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_spam(s):\n",
    "    return spam_filter.predict([s])[0] \n",
    "detect_spam(\"hello preetham how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
